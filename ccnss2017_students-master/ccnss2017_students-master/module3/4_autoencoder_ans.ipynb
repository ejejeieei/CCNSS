{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrence, Depth and High-dimensional data\n",
    "# Autoencoder notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we introduce autoencoders, which perform unsupervised learning of the train set by forcing a compression of the latent space. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Please execute the cell bellow in order to initialize the notebook environment*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autosave 0\n",
    "# %matplotlib inline\n",
    "%matplotlib notebook\n",
    "\n",
    "from __future__ import division, print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import mod3\n",
    "\n",
    "plt.rcParams.update({'figure.figsize': (5.0, 4.0), 'lines.linewidth': 2.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST dataset import and pre-processing\n",
    "\n",
    "*Please execute the cell bellow in order to prepare the MNIST dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train[:, ::2, ::2].copy()\n",
    "x_test = x_test[:, ::2, ::2].copy()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "x_shape = x_train.shape[1:]\n",
    "\n",
    "print('train set shape:', x_train.shape)\n",
    "print('test set shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "n_epochs = 5\n",
    "encoding_dim = 32\n",
    "\n",
    "input_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "input_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "input_train_shape = input_train.shape[1]\n",
    "\n",
    "input_layer = Input(shape=(input_train_shape,))\n",
    "encoded = Dense(encoding_dim, activation='relu', name='encoded')(input_layer)\n",
    "decoded = Dense(input_train_shape, activation='sigmoid')(encoded)\n",
    "\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "autoencoder.summary()\n",
    "\n",
    "history = autoencoder.fit(input_train, input_train,\n",
    "                          epochs=n_epochs,\n",
    "                          batch_size=32,\n",
    "                          shuffle=True,\n",
    "                          validation_data=(input_test, input_test))\n",
    "\n",
    "output_test = autoencoder.predict(input_test)\n",
    "\n",
    "plt.figure(figsize=(9, 2))\n",
    "mod3.plot_generated(input_test, output_test, x_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXPECTED OUTPUT**\n",
    "```\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_1 (InputLayer)         (None, 196)               0         \n",
    "_________________________________________________________________\n",
    "encoded (Dense)              (None, 32)                6304      \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 196)               6468      \n",
    "=================================================================\n",
    "Total params: 12,772.0\n",
    "Trainable params: 12,772.0\n",
    "Non-trainable params: 0.0\n",
    "_________________________________________________________________\n",
    "Train on 60000 samples, validate on 10000 samples\n",
    "Epoch 1/5\n",
    "60000/60000 [==============================] - 5s - loss: 0.2410 - val_loss: 0.1783\n",
    "Epoch 2/5\n",
    "60000/60000 [==============================] - 6s - loss: 0.1590 - val_loss: 0.1417\n",
    "Epoch 3/5\n",
    "60000/60000 [==============================] - 5s - loss: 0.1324 - val_loss: 0.1221\n",
    "Epoch 4/5\n",
    "60000/60000 [==============================] - 5s - loss: 0.1174 - val_loss: 0.1108\n",
    "Epoch 5/5\n",
    "60000/60000 [==============================] - 5s - loss: 0.1084 - val_loss: 0.1039\n",
    "```\n",
    "<img src=\"fig/autoencoder_simple.png\" style=\"width:90%;height:90%;display:inline;margin:1px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "encoding_dim = 32\n",
    "noise_factor = 0.2\n",
    "\n",
    "input_train_noisy = input_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=input_train_shape) \n",
    "input_test_noisy = input_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=input_train_shape) \n",
    "\n",
    "input_train_noisy = np.clip(input_train_noisy, 0., 1.)\n",
    "input_test_noisy = np.clip(input_test_noisy, 0., 1.)\n",
    "\n",
    "input_layer = Input(shape=(input_train_shape,))\n",
    "encoded = Dense(encoding_dim, activation='relu', name='encoded')(input_layer)\n",
    "decoded = Dense(input_train_shape, activation='sigmoid')(encoded)\n",
    "\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "history = autoencoder.fit(input_train_noisy, input_train,\n",
    "                          epochs=n_epochs)\n",
    "\n",
    "output_test = autoencoder.predict(input_test)\n",
    "\n",
    "plt.figure(figsize=(9, 2))\n",
    "mod3.plot_generated(input_test_noisy, output_test, x_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXPECTED OUTPUT**\n",
    "```\n",
    "Epoch 1/5\n",
    "60000/60000 [==============================] - 5s - loss: 0.2355     \n",
    "Epoch 2/5\n",
    "60000/60000 [==============================] - 4s - loss: 0.1583     \n",
    "Epoch 3/5\n",
    "60000/60000 [==============================] - 4s - loss: 0.1335     \n",
    "Epoch 4/5\n",
    "60000/60000 [==============================] - 4s - loss: 0.1198     \n",
    "Epoch 5/5\n",
    "60000/60000 [==============================] - 5s - loss: 0.1116\n",
    "```\n",
    "<img src=\"fig/autoencoder_denoise.png\" style=\"width:90%;height:90%;display:inline;margin:1px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extended exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXTENDED EXERCISE 1**\n",
    "\n",
    "How does the size of the bottleneck layer affect the effectiveness of the denoising autoencoder? For instance, compare the output to the input images, and investigate the effects of noise magnitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXTENDED EXERCISE 2**\n",
    "\n",
    "The basic autoencoder model presented in this notebook performs compression of the input space due to the smaller dimension of the bottleneck layer.\n",
    "\n",
    "How does this compression compare to popular methods of dimensionality reduction such as PCA."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
