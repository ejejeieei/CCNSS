{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrence, Depth and High-dimensional data\n",
    "# High dimensionality visualization notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we present several techniques of high dimensional data visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Please execute the cell bellow in order to initialize the notebook environment*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autosave 0\n",
    "# %matplotlib inline\n",
    "%matplotlib notebook\n",
    "\n",
    "from __future__ import division, print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import mod3\n",
    "\n",
    "plt.rcParams.update({'figure.figsize': (5.0, 4.0), 'lines.linewidth': 2.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST dataset import and pre-processing\n",
    "\n",
    "*Please execute the cell bellow in order to prepare the MNIST dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train[:, ::2, ::2].copy()\n",
    "x_test = x_test[:, ::2, ::2].copy()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "x_shape = x_train.shape[1:]\n",
    "\n",
    "# keep only certain classes\n",
    "x_train = x_train[(y_train==0) | (y_train==1) | (y_train==2) | (y_train==3)\n",
    "                  | (y_train==4) | (y_train==5)]\n",
    "y_train = y_train[(y_train==0) | (y_train==1) | (y_train==2) | (y_train==3)\n",
    "                  | (y_train==4) | (y_train==5)]\n",
    "\n",
    "x_test = x_test[(y_test==0) | (y_test==1) | (y_test==2) | (y_test==3)\n",
    "                  | (y_test==4) | (y_test==5)]\n",
    "y_test = y_test[(y_test==0) | (y_test==1) | (y_test==2) | (y_test==3)\n",
    "                  | (y_test==4) | (y_test==5)]\n",
    "\n",
    "print('train set shape:', x_train.shape)\n",
    "print('test set shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST on PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import manifold, decomposition\n",
    "\n",
    "n_show = 500\n",
    "\n",
    "input_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "\n",
    "pca = decomposition.PCA(n_components=2).fit(input_train)\n",
    "\n",
    "output_train = pca.transform(input_train)\n",
    "output_train_inv = pca.inverse_transform(output_train)\n",
    "\n",
    "plt.figure(figsize=(9, 2))\n",
    "mod3.plot_generated(input_train, output_train_inv, x_shape)\n",
    "\n",
    "mod3.plot_embedding(output_train[:n_show], y_train[:n_show], 'PCA projection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST on t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_show = 500\n",
    "\n",
    "x_train_reduced = x_train[:5000]\n",
    "\n",
    "input_train = x_train_reduced.reshape((len(x_train_reduced), np.prod(x_train_reduced.shape[1:])))\n",
    "\n",
    "output_train = manifold.TSNE(n_components=2, init='pca', verbose=1).fit_transform(input_train)\n",
    "\n",
    "mod3.plot_embedding(output_train[:n_show], y_train[:n_show], 't-SNE projection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extended exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXTENDED EXERCISE 1**\n",
    "\n",
    "The bottleneck layer of the autoencoder provides a latent representation of the dataset.\n",
    "\n",
    "Characterize the representation of the bottleneck layer using dimensionality reduction techniques (PCA, t-SNE). How does this compare to the input representations?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
