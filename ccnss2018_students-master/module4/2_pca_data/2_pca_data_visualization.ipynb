{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_pca_data_visualization",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1f0fDwkmvyFC_2ZPTL9vQgIm_UaUeTxAc",
          "timestamp": 1524738812951
        }
      ],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "TpnOn58EgfaE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## CCNSS 2018 Module 4: High dimensional representations and neural dynamics\n",
        "# Tutorial 2: Visualization and tools to characterize high-dimensional spaces\n",
        "\n",
        "[source](https://colab.research.google.com/drive/1OouBcak6NF3hli4cDwfZZwdrVSuzKxS1)"
      ]
    },
    {
      "metadata": {
        "id": "hi2UOXjigfaF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*Please execute the cell bellow in order to initialize the notebook environment*"
      ]
    },
    {
      "metadata": {
        "id": "nJgJVfSugfaG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt    # import matplotlib\n",
        "import matplotlib as mp\n",
        "import numpy as np                 # import numpy\n",
        "import math                        # import basic math functions\n",
        "import random                      # import basic random number generator functions\n",
        "from google.colab import files\n",
        "from scipy.io import loadmat \n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "fig_w, fig_h = (6, 4)\n",
        "plt.rcParams.update({'figure.figsize': (fig_w, fig_h)})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cmL_5NaAiFen",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!if [ ! -d data ]; then git clone https://github.com/ccnss/ccnss2018_students; \\\n",
        "                        cp -rf ccnss2018_students/module4/2_pca_data/data ./; fi\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "data_folder = 'data'\n",
        "\n",
        "print('Available data files:', ' '.join(os.listdir('data')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UwXIfh1Y9j66",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Objectives\n",
        "\n",
        "In this notebook we will analyze real high-dimensional data sets and find low-dimensional subspaces that characterize the data. We will relate the eigenvalues of the covariance matrix to the variance of the data and how we can use this to approximate the dimension of the subspace where the data resides.  "
      ]
    },
    {
      "metadata": {
        "id": "HU7L6JxVgfaK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Background\n",
        "\n",
        "We will continue the previous tutorial on PCA. We we will look at high dimensional spike-count data. In particular, we will:\n",
        "\n",
        "\n",
        "* Use spike-count data and calculate its principal components.\n",
        "* We will calculate and plot the eigenvalue spectrum and qualitatively and quantitatively reduce the dimensionality of the data set. \n",
        "* Use factor analysis applied on the same data set and compare the results to the results obtained with PCA\n",
        "\n",
        "\n",
        "In the first three exercises, we will characterize the data \"blindly\", i.e., without regards to its content. \n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "L58fdqcNgfaM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**EXERCISE 1**\n",
        "\n",
        "• Import the data from using the function \"loadmat\" from the the scipy package. The data is a 728 × 97 matrix of real data, where each row is a spike count vector across 97 simultaneously-recorded neurons. We are providing you here with the spike counts rather than the raw spike trains, where the spike counts are taken in a 200 ms bin during the plan period. (data courtesy from the Krishna Shenoy Lab). D = 97 is the dimensionality of the data. \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "xTPDd7-yznXs",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "data_file = os.path.join(data_folder, 'ps8_data.mat')\n",
        "data_all = loadmat(data_file)\n",
        "data_matrix = data_all['Xplan']\n",
        "shape = np.shape(data_matrix)\n",
        "print(shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LC56amWvgfaZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "- Calculate the covariance matrix for this data and print the output.\n"
      ]
    },
    {
      "metadata": {
        "id": "XOz_qKiJvcKj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#Insert code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uOtweCUuxZ5J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Expected output:###\n",
        "```\n",
        "Y(cov_matrix) =  [[ 5.48114471  0.63030016 -0.70472316 ...  1.60418994  1.39284771\n",
        "   0.65848214]\n",
        " [ 0.63030016  1.69980792 -0.15368766 ...  0.44110954  0.09691802\n",
        "   0.14508929]\n",
        " [-0.70472316 -0.15368766  1.42962806 ... -0.5488694  -0.73156171\n",
        "  -0.22733516]\n",
        " ...\n",
        " [ 1.60418994  0.44110954 -0.5488694  ... 12.08860456  1.35253706\n",
        "   1.48197115]\n",
        " [ 1.39284771  0.09691802 -0.73156171 ...  1.35253706  3.77345543\n",
        "   0.68526786]\n",
        " [ 0.65848214  0.14508929 -0.22733516 ...  1.48197115  0.68526786\n",
        "   3.36349588]]\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "5eUyc5fwvaA3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "DtVAnrjzgfaa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**EXERCISE 2**\n",
        "\n",
        "- Plot the eigenvalue spectrum. **Hint**: use the function np.linalg.eig.\n",
        "\n",
        " If you had to identify an\n",
        "elbow in the eigenvalue spectrum, how many dominant eigenvalues would there be? "
      ]
    },
    {
      "metadata": {
        "id": "24Cf1zA0vrtC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Insert code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_AHDGwEc0Zdd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Expected output:###\n",
        "\n",
        "\n",
        "![](https://github.com/ccnss/ccnss2018_students/raw/master/module4/2_pca_data/figures/Mod4T2E2.png)"
      ]
    },
    {
      "metadata": {
        "id": "dBaNGN8vJrbM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**EXERCISE 3**\n",
        "\n",
        "- What percentage of the overall variance is captured by the top 3 principal components (corresponding to the three dominant eigenvalues)?\n",
        "Hint: The overall variance is given by the trace of the covariance matrix, which coincides with the sum of the eigenvalues. \n"
      ]
    },
    {
      "metadata": {
        "id": "YfGinZ3qvukJ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Insert code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sfN2V_sx4_8c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Expected output:###\n",
        "\n",
        "\n",
        "```\n",
        "3eigval_percent =  44.790993553148\n",
        "```\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Q1ViIKL04LtK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- Plot the fraction of explained variance as a function of eigenvalue/principal component number (The x axis is thus serially ordered: 1, 2, ..97.). On top of that plot, plot the cumulative variance. How many principal components do you need to explain 80% of the variance? "
      ]
    },
    {
      "metadata": {
        "id": "k94omLd9v7_k",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Insert code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hn6Reg522gRu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Expected output:###\n",
        "\n",
        "![](https://github.com/ccnss/ccnss2018_students/raw/master/module4/2_pca_data/figures/Mod4T2E3.png)"
      ]
    },
    {
      "metadata": {
        "id": "CmrrLOob2iKo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "- Check that the three eigenvectors are orthogonal. "
      ]
    },
    {
      "metadata": {
        "id": "aeVWYeOfv5LL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Insert code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1MJG1dNv-JE8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Expected output:###\n",
        "```12dot =  3.622102617839573e-15\n",
        "23dot =  -1.8370721610594387e-15\n",
        "13dot =  -4.996003610813204e-16```"
      ]
    },
    {
      "metadata": {
        "id": "W3l88MW_HGTl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**EXERCISE 4**\n",
        "\n",
        "##Background:\n",
        "We will now look at the data set more closely. The data set was collected during a reaching task for which there were 8 reaching angles in total. There are 91 trials for each of 8 reaching angles, for a total of 728 trials. Trials 1 to 91 correspond\n",
        "to reaching angle 1, trials 92 to 182 correspond to reach angle 2, etc.\n",
        "\n",
        "For the purposes of visualization, we’ll consider the PC space defined\n",
        "by the top M = 3 eigenvectors and project the data into the three-dimensional PC\n",
        "space. \n",
        "\n",
        "- First, write a function \"projections\" that returns projections of a matrix onto an aribitrary vector. Calculate the projection of the data matrix onto each of the 3 principal components. Print the variance of each of the projections.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "nxoe8U-Jv_rY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# insert code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GIfXaNe6wHcI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Expected output ###\n",
        "```\n",
        "var1 = 73.92634407392778\n",
        "var2 = 51.72433194336624\n",
        "var3 = 44.066740370624785\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "ffJNPRiSAFC7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "- Plot the projected points in matplotlib using ax = fig.add_subplot(111, projection='3d') and ax.scatter\n",
        " , and color each dot\n",
        "appropriately according to reaching angle (there should be a total of 728 dots, 91 for each angle). Show a view in\n",
        "which the clusters are well-separated by using ax.view_init(a) where a is a rotation angle. \n"
      ]
    },
    {
      "metadata": {
        "id": "f2BbW0TPwNSg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "## Insert code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KGh6obHoGqr1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Expected output ###\n",
        "![](https://github.com/ccnss/ccnss2018_students/raw/master/module4/2_pca_data/figures/Mod4T2E4.png)"
      ]
    },
    {
      "metadata": {
        "id": "y82jOtCrAg84",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- How does the variance of the projections along the eigenvectors relate to the corresponding eigenvalues?"
      ]
    },
    {
      "metadata": {
        "id": "QQHY4O_owSFH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "## Insert code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DOGqwfHVdwwR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- In the 3-PC space, plot the centroid of the dot pattern, for each angle. The centroid is essentially the mean over the three directions. You should obtain a plot with 8 colored dots. \\\n",
        "\n",
        "How do you think these clusters map onto physical (reach angle space)?"
      ]
    },
    {
      "metadata": {
        "id": "dh2ZmdzfwW3R",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "### Insert code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s2DTfGqbGzml",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Expected output ###\n",
        "![](https://github.com/ccnss/ccnss2018_students/raw/master/module4/2_pca_data/figures/Mod4T2E4b.png)"
      ]
    },
    {
      "metadata": {
        "id": "rOvyWz7RaJJ8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- Plot the projections of the centroids onto PC1 as a function of angle/stimulus index. This constitutes a tuning curve for the population. "
      ]
    },
    {
      "metadata": {
        "id": "1zEinugZwaN_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "### Isert code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YHBs-Qo9How1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Expected output ###\n",
        "![](https://github.com/ccnss/ccnss2018_students/raw/master/module4/2_pca_data/figures/Mod4T2E4c.png)"
      ]
    },
    {
      "metadata": {
        "id": "wMjbWF95g6wv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- BONUS: Plot the single-neuron tuning curves for the neurons that:\n",
        "1) contribute most and 2) least to the variance in PC1. Hint: Use np.argmax(np.abs(PC1)) and np.argmin(np.abs(PC1))to obtain the indices of these neurons. "
      ]
    },
    {
      "metadata": {
        "id": "kk62VATwIKCn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Expected output ###\n",
        "![](https://github.com/ccnss/ccnss2018_students/raw/master/module4/2_pca_data /figures/Mod4T2E4d.png)"
      ]
    },
    {
      "metadata": {
        "id": "N1dx-Jile1cx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "STILL HAVE TIME? Optional Exercise:\n",
        "\n",
        "\n",
        "In this exercise, you will apply PCA to a few training examples included in the well-known data set: the MNIST data set of handwritten digits. First, execute the cell below to import the MNIST data set. After executing the cell, the **only variables** you will use are: \n",
        " **x_train** (an array of 14x14 images containing examples of the digits 0-5) and **y_train** (a vector of indices for the five digits)\n",
        " \n",
        " "
      ]
    },
    {
      "metadata": {
        "id": "es23HDsgTrpf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train[:, ::2, ::2].copy()\n",
        "x_test = x_test[:, ::2, ::2].copy()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "x_shape = x_train.shape[1:]\n",
        "\n",
        "# keep only certain classes\n",
        "x_train = x_train[(y_train==0) | (y_train==1) | (y_train==2) | (y_train==3)\n",
        "                  | (y_train==4) | (y_train==5)]\n",
        "y_train = y_train[(y_train==0) | (y_train==1) | (y_train==2) | (y_train==3)\n",
        "                  | (y_train==4) | (y_train==5)]\n",
        "\n",
        "x_test = x_test[(y_test==0) | (y_test==1) | (y_test==2) | (y_test==3)\n",
        "                  | (y_test==4) | (y_test==5)]\n",
        "y_test = y_test[(y_test==0) | (y_test==1) | (y_test==2) | (y_test==3)\n",
        "                  | (y_test==4) | (y_test==5)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mdCOr_rlKtP3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- make new arrays x_train_0 and x_train_1 that contain only the digits \"0\" and \"1\", respectively. Plot the first three images for each array, i.e., the first three \"0\"s and first three \"1\"s. Hint: Use the vector y_train for this. "
      ]
    },
    {
      "metadata": {
        "id": "ZfzmHpoZwrT0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "## insert code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QmqzytGkTob7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Expected output ###\n",
        "![](https://github.com/ccnss/ccnss2018_students/raw/master/module4/2_pca_data/figures/Mod4T2E5.png)"
      ]
    },
    {
      "metadata": {
        "id": "bsZnxFEUTxju",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Expected output ###\n",
        "![](https://github.com/ccnss/ccnss2018_students/raw/master/module4/2_pca_data /figures/Mod4T2E5a.png)"
      ]
    },
    {
      "metadata": {
        "id": "iXcIiVG0Lu71",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- Given the arrays x_train_0 and x_train_1 above, form a new array x_train_01 that concatenates both arrays. Hint: Use the function np.vstack. Print the shape of your new array x_train_01 . \n"
      ]
    },
    {
      "metadata": {
        "id": "ObEeHjCQwzVu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Expected ouput ###\n",
        "```\n",
        "(12665, 14, 14)\n",
        "```\n"
      ]
    },
    {
      "metadata": {
        "id": "DkVt2IlUM4Wv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will perform PCA on this new array x_train01. For this, we will import the function *decomposition* from the library *sklearn* to peform PCA on our data set. Note that to compute PCA we first need to reshape our images of dim 14x14 and transform them into vectors of length 196. Execute the cell below"
      ]
    },
    {
      "metadata": {
        "id": "qoZ2IyOCTs9Q",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn import decomposition\n",
        "\n",
        "input_train = x_train_01.reshape((len(x_train_01), np.prod(x_train_01.shape[1:])))\n",
        "\n",
        "pca = decomposition.PCA(n_components=2).fit(input_train)\n",
        "\n",
        "output_train = pca.transform(input_train)\n",
        "output_train_inv = pca.inverse_transform(output_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Htz_P6eaPjyi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The relevant variables from this cell are: \n",
        " output_train (result of PCA transform on your input)\n",
        " output_train_inv (result of recovering the original variable after having selected its two first components). Print the shapes of these two variables. "
      ]
    },
    {
      "metadata": {
        "id": "XkXJ1-N4Qbyt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- Plot the first image stored in output_train_inv. Hint: Note that the shape of the images are now vectors; you need to reshape these images to obtain images with dim 14x14. Use the function np.reshape as np.reshape(vector, shape), where vector is your input vector, and shape is the new shape you want to transform the vector to (in this case, 14x14).\n",
        "\n",
        "How does this recoved image compare to the original one?"
      ]
    },
    {
      "metadata": {
        "id": "gt38_oXsV__c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Expected output ###\n",
        "![](https://github.com/ccnss/ccnss2018_students/raw/master/module4/2_pca_data/figures/Mod4T2E5a.png)"
      ]
    },
    {
      "metadata": {
        "id": "HuZs_RU8RxIj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- The variable output_train contains the projections of the \"0\" and \"1\" images onto the principal components. Plot the first 500 images for each set of \"0\" and \"1\", using two different colors, respectively. Are the clusters well separated? "
      ]
    },
    {
      "metadata": {
        "id": "hTpM9c_qIFlP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Expected output ###\n",
        "![](https://github.com/ccnss/ccnss2018_students/raw/master/module4/2_pca_data/figures/Mod4T2E5b.png)"
      ]
    }
  ]
}